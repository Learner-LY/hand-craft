{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样三步走：数据加载及预处理；模型构建；训练以及评测使用；\n",
    "\n",
    "Data Path:/home/ly/pytorch_exercise/data/data-for-gene-names/;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part1:读入以及准备数据;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from io import open\n",
    "import os\n",
    "import string\n",
    "fileList=os.listdir('/home/ly/pytorch_exercise/data/data-for-classify-names')\n",
    "for i in range(len(fileList)):\n",
    "    fileList[i]=fileList[i].split('.')[0]\n",
    "filepath='/home/ly/pytorch_exercise/data/data-for-classify-names/'\n",
    "dic={}\n",
    "#不同语言之间字符编码格式转换;\n",
    "import unicodedata\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "n_letters = len(all_letters)+1  # Plus EOS marker;  换一种表征方式(不可行,因为loss function的输入形式的要求);\n",
    "                                                                                  #上一个任务根本不需要结束标志符啊!\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "for files in fileList:\n",
    "    dic[files]=open(filepath+files+'.txt').read().strip().split('\\n')\n",
    "for files in fileList:\n",
    "    for i in range(len(dic[files])):\n",
    "        dic[files][i]=unicodeToAscii(dic[files][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def wordToTensor(s):\n",
    "    temp=torch.zeros(len(s),1,n_letters)\n",
    "    for i in range(len(s)):\n",
    "        for j in range(n_letters):\n",
    "            if all_letters[j]==s[i]:\n",
    "                temp[i][0][j]=1\n",
    "                break\n",
    "    return temp\n",
    "def targetToTensor(s):\n",
    "    temp=torch.zeros(len(s),1,1)\n",
    "    for i in range(1,len(s)):\n",
    "        for j in range(n_letters):\n",
    "            if all_letters[j]==s[i-1]:\n",
    "                temp[i-1][0][0]=j\n",
    "                break\n",
    "    temp[i][0][0]=58\n",
    "    return temp\n",
    "def categoryToTensor(n):\n",
    "    temp=torch.zeros(18)\n",
    "    temp[n-1]=1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "dicTensor=deepcopy(dic)\n",
    "targetTensor=deepcopy(dic)\n",
    "for i in range(len(dic.keys())):\n",
    "    for j in range(len(dic[dic.keys()[i]])):\n",
    "        dicTensor[dic.keys()[i]][j]=wordToTensor(dic[dic.keys()[i]][j])\n",
    "        targetTensor[dic.keys()[i]][j]=targetToTensor(dic[dic.keys()[i]][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#一个单词是一个训练样本;\n",
    "#关于训练数据表征方面,向量长度相较上一个任务应该增加一个长度,因为要表征<EOS>结束符;\n",
    "#也可以不增加长度,把<EOS>表征为全0向量即可;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part2:定义网络结构;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,category_size,input_size,hidden_size,output_size):\n",
    "        super(RNN,self).__init__()\n",
    "        self.hidden_size=hidden_size\n",
    "        self.i2h=nn.Linear(category_size+input_size+hidden_size,hidden_size)\n",
    "        self.i2o=nn.Linear(category_size+input_size+hidden_size,output_size)\n",
    "        self.o2o=nn.Linear(hidden_size+output_size,output_size)\n",
    "        self.dropout=nn.Dropout(0.5)\n",
    "        self.softmax=nn.LogSoftmax()\n",
    "    def forward(self,categoryTensor,inputTensor,hiddenTensor):\n",
    "        input_combined1=torch.cat((categoryTensor,inputTensor),1)\n",
    "        #cat不能同时cat三个!!\n",
    "        input_combined=torch.cat((input_combined1,hiddenTensor),1)\n",
    "        hidden=self.i2h(input_combined)\n",
    "        output=self.i2o(input_combined)\n",
    "        output_combined=torch.cat((hidden,output),1)\n",
    "        output=self.o2o(output_combined)\n",
    "        output=self.dropout(output)\n",
    "        output=self.softmax(output)\n",
    "        return output,hidden\n",
    "    def initHidden(self):\n",
    "        hidden=torch.zeros(1,self.hidden_size)\n",
    "        return Variable(hidden)\n",
    "n_hidden=128\n",
    "n_categories=len(dic.keys())\n",
    "rnn=RNN(n_categories,n_letters,n_hidden,n_letters)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size,C_size):   #将几个单元的output_size设置为同一长度;\n",
    "        super(LSTM,self).__init__()\n",
    "        self.hidden_size=hidden_szie\n",
    "        self.C_size=C_size\n",
    "        self.i2F=nn.Linear(input_size+hidden_size,1)\n",
    "        self.i2I=nn.Linear(input_size+hidden_size,1)\n",
    "        self.i2C=nn.Linear(input_size+hidden_size,output_size)\n",
    "        self.i2O=nn.Linear(input_size+hidden_size,1)\n",
    "    def forward(self,inputTensor,hiddenTensor,CTensor):\n",
    "        input_combined=torch.cat((inputTensor,hiddenTensor),1)\n",
    "        f=torch.sigmoid(self.i2F(input_combined))\n",
    "        i=torch.sigmoid(self.i2I(input_combined))\n",
    "        C_hat=torch.tanh(self.i2C(input_combined))\n",
    "        #这点不对,torch里怎么进行广播机制,如何让一个数和一个矩阵相乘??\n",
    "        CTensor_numpy=CTensor.numpy()\n",
    "        C_hat_numpy=C_hat.numpy()\n",
    "        f_numpy=f.numpy()\n",
    "        i_numpy=i.numpy()\n",
    "        CTensor=torch.from_numpy(f_numpy*CTensor_numpy+i_numpy*C_hat_numpy)\n",
    "        #CTensor=f*CTensor+i*C_hat\n",
    "        O=torch.sigmoid(self.i2O(input_combined,1))\n",
    "        hiddenTensor=O*torch.tanh(C)\n",
    "        return CTensor,hiddenTensor\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1,self.hidden_size))\n",
    "    def initCTensor(self):\n",
    "        return Variable(torch.zeros(1,self.C_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part3:begin to train;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate=0.005\n",
    "def train(category_tensor, input_line_tensor, target_line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "    rnn.zero_grad()\n",
    "    loss = 0\n",
    "    for i in range(input_line_tensor.size()[0]):\n",
    "        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n",
    "        loss += criterion(output, target_line_tensor[i][0].long())\n",
    "    loss.backward()\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "    return output, loss.data[0] / input_line_tensor.size()[0]\n",
    "def category_one_hot(n):\n",
    "    temp=torch.zeros(1,n_categories)\n",
    "    for i in range(n_categories):\n",
    "        if i==n:\n",
    "            temp[0][i]=1\n",
    "            break\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 0s (0 0%) 2.3721\n",
      "0m 2s (100 0%) 3.7003\n",
      "0m 3s (200 0%) 2.1352\n",
      "0m 5s (300 0%) 2.3415\n",
      "0m 6s (400 0%) 2.6146\n",
      "0m 8s (500 0%) 3.6200\n",
      "0m 9s (600 0%) 2.8616\n",
      "0m 11s (700 0%) 2.7364\n",
      "0m 13s (800 0%) 2.8849\n",
      "0m 14s (900 0%) 2.6808\n",
      "0m 16s (1000 0%) 3.7552\n",
      "0m 24s (1100 0%) 2.6164\n",
      "0m 30s (1200 0%) 2.5775\n",
      "0m 36s (1300 0%) 2.3154\n",
      "0m 42s (1400 0%) 2.5867\n",
      "0m 48s (1500 0%) 1.5939\n",
      "0m 54s (1600 0%) 2.1089\n",
      "1m 0s (1700 0%) 2.1530\n",
      "1m 6s (1800 0%) 2.8000\n",
      "1m 11s (1900 0%) 1.9562\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "n_iters=2000\n",
    "plot_every=100\n",
    "print_every=100\n",
    "all_loss=[]\n",
    "total_loss=0\n",
    "start=time.time()\n",
    "for iter in range(n_iters):\n",
    "    n=random.randint(0,n_categories-1)\n",
    "    m=random.randint(0,len(dic[dic.keys()[n]])-1)\n",
    "    categoryTensor=Variable(category_one_hot(n))\n",
    "    inputTensor=Variable(dicTensor[dic.keys()[n]][m])\n",
    "    target=Variable(targetTensor[dic.keys()[n]][m])\n",
    "    output,loss=train(categoryTensor,inputTensor,target)\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_loss.append(total_loss / plot_every)\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part4:验证展示;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f570f3412d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "plt.figure()\n",
    "plt.plot(all_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#给一个类别,一个首字符,进行字符串生成;下一时刻的输入是上一时刻的输出预测值;\n",
    "max_len=30\n",
    "def sample(category,start_letter):\n",
    "    re=start_letter\n",
    "    category_tensor=Variable(category_one_hot(category))\n",
    "    start_tensor=Variable(wordToTensor(start_letter)[0])\n",
    "    hidden=rnn.initHidden()\n",
    "    for i in range(max_len):\n",
    "        output,hidden=rnn(category_tensor,start_tensor,hidden)\n",
    "        topv,topi=output.data.topk(1)\n",
    "        topi=topi[0][0]\n",
    "        if topi==n_letters-1:\n",
    "            break\n",
    "        else:\n",
    "            re+=all_letters[topi]\n",
    "        start_tensor=Variable(wordToTensor(all_letters[topi])[0])\n",
    "    return re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "s=sample(2,'e')\n",
    "print s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#调试代码,调出了一个bug:RuntimeError: Assertion `cur_target >= 0 && cur_target < n_classes' failed. \n",
    "#出现这个bug的原因是网络结构中output_size弄错了!\n",
    "hidden=rnn.initHidden()\n",
    "category_tensor=Variable(category_one_hot(2))\n",
    "input_tensor=Variable(wordToTensor(dic['Chinese'][0]))\n",
    "output,hidden=rnn(category_tensor,input_tensor[0],hidden)\n",
    "a1=Variable(torch.LongTensor([25]))\n",
    "loss=criterion(output,a1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

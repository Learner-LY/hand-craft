{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样三步走：数据加载及预处理；模型构建；训练以及评测使用；\n",
    "\n",
    "Data Path:/home/ly/pytorch_exercise/data/data-for-gene-names/;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part1:读入以及准备数据;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from io import open\n",
    "import os\n",
    "import string\n",
    "fileList=os.listdir('/home/ly/pytorch_exercise/data/data-for-classify-names')\n",
    "for i in range(len(fileList)):\n",
    "    fileList[i]=fileList[i].split('.')[0]\n",
    "filepath='/home/ly/pytorch_exercise/data/data-for-classify-names/'\n",
    "dic={}\n",
    "#不同语言之间字符编码格式转换;\n",
    "import unicodedata\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "n_letters = len(all_letters)+1  # Plus EOS marker;  换一种表征方式(不可行,因为loss function的输入形式的要求);\n",
    "                                                                                  #上一个任务根本不需要结束标志符啊!\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "for files in fileList:\n",
    "    dic[files]=open(filepath+files+'.txt').read().strip().split('\\n')\n",
    "for files in fileList:\n",
    "    for i in range(len(dic[files])):\n",
    "        dic[files][i]=unicodeToAscii(dic[files][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def wordToTensor(s):\n",
    "    temp=torch.zeros(len(s),1,n_letters)\n",
    "    for i in range(len(s)):\n",
    "        for j in range(n_letters):\n",
    "            if all_letters[j]==s[i]:\n",
    "                temp[i][0][j]=1\n",
    "                break\n",
    "    return temp\n",
    "def targetToTensor(s):\n",
    "    temp=torch.zeros(len(s),1,1)\n",
    "    for i in range(1,len(s)):\n",
    "        for j in range(n_letters):\n",
    "            if all_letters[j]==s[i-1]:\n",
    "                temp[i-1][0][0]=j\n",
    "                break\n",
    "    temp[i][0][0]=58\n",
    "    return temp\n",
    "def categoryToTensor(n):\n",
    "    temp=torch.zeros(18)\n",
    "    temp[n-1]=1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "dicTensor=deepcopy(dic)\n",
    "targetTensor=deepcopy(dic)\n",
    "for i in range(len(dic.keys())):\n",
    "    for j in range(len(dic[dic.keys()[i]])):\n",
    "        dicTensor[dic.keys()[i]][j]=wordToTensor(dic[dic.keys()[i]][j])\n",
    "        targetTensor[dic.keys()[i]][j]=targetToTensor(dic[dic.keys()[i]][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#一个单词是一个训练样本;\n",
    "#关于训练数据表征方面,向量长度相较上一个任务应该增加一个长度,因为要表征<EOS>结束符;\n",
    "#也可以不增加长度,把<EOS>表征为全0向量即可;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part2:定义网络结构;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,category_size,input_size,hidden_size,output_size):\n",
    "        super(RNN,self).__init__()\n",
    "        self.hidden_size=hidden_size\n",
    "        self.i2h=nn.Linear(category_size+input_size+hidden_size,hidden_size)\n",
    "        self.i2o=nn.Linear(category_size+input_size+hidden_size,output_size)\n",
    "        self.o2o=nn.Linear(hidden_size+output_size,output_size)\n",
    "        self.dropout=nn.Dropout(0.5)\n",
    "        self.softmax=nn.LogSoftmax()\n",
    "    def forward(self,categoryTensor,inputTensor,hiddenTensor):\n",
    "        input_combined1=torch.cat((categoryTensor,inputTensor),1)\n",
    "        #cat不能同时cat三个!!\n",
    "        input_combined=torch.cat((input_combined1,hiddenTensor),1)\n",
    "        hidden=self.i2h(input_combined)\n",
    "        output=self.i2o(input_combined)\n",
    "        output_combined=torch.cat((hidden,output),1)\n",
    "        output=self.o2o(output_combined)\n",
    "        output=self.dropout(output)\n",
    "        output=self.softmax(output)\n",
    "        return output,hidden\n",
    "    def initHidden(self):\n",
    "        hidden=torch.zeros(1,self.hidden_size)\n",
    "        return Variable(hidden)\n",
    "n_hidden=128\n",
    "n_categories=len(dic.keys())\n",
    "rnn=RNN(n_categories,n_letters,n_hidden,n_letters)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size,C_size):   #将几个单元的output_size设置为同一长度;\n",
    "        super(LSTM,self).__init__()\n",
    "        self.hidden_size=hidden_szie\n",
    "        self.C_size=C_size\n",
    "        self.i2F=nn.Linear(input_size+hidden_size,1)\n",
    "        self.i2I=nn.Linear(input_size+hidden_size,1)\n",
    "        self.i2C=nn.Linear(input_size+hidden_size,output_size)\n",
    "        self.i2O=nn.Linear(input_size+hidden_size,1)\n",
    "    def forward(self,inputTensor,hiddenTensor,CTensor):\n",
    "        input_combined=torch.cat((inputTensor,hiddenTensor),1)\n",
    "        f=torch.sigmoid(self.i2F(input_combined))\n",
    "        i=torch.sigmoid(self.i2I(input_combined))\n",
    "        C_hat=torch.tanh(self.i2C(input_combined))\n",
    "        #这点不对,torch里怎么进行广播机制,如何让一个数和一个矩阵相乘??\n",
    "        CTensor_numpy=CTensor.numpy()\n",
    "        C_hat_numpy=C_hat.numpy()\n",
    "        f_numpy=f.numpy()\n",
    "        i_numpy=i.numpy()\n",
    "        CTensor=torch.from_numpy(f_numpy*CTensor_numpy+i_numpy*C_hat_numpy)\n",
    "        #CTensor=f*CTensor+i*C_hat\n",
    "        O=torch.sigmoid(self.i2O(input_combined,1))\n",
    "        hiddenTensor=O*torch.tanh(C)\n",
    "        return CTensor,hiddenTensor\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1,self.hidden_size))\n",
    "    def initCTensor(self):\n",
    "        return Variable(torch.zeros(1,self.C_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part3:begin to train;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate=0.005\n",
    "def train(category_tensor, input_line_tensor, target_line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "    rnn.zero_grad()\n",
    "    loss = 0\n",
    "    for i in range(input_line_tensor.size()[0]):\n",
    "        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n",
    "        loss += criterion(output, target_line_tensor[i][0].long())\n",
    "    loss.backward()\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "    return output, loss.data[0] / input_line_tensor.size()[0]\n",
    "def category_one_hot(n):\n",
    "    temp=torch.zeros(1,n_categories)\n",
    "    for i in range(n_categories):\n",
    "        if i==n:\n",
    "            temp[0][i]=1\n",
    "            break\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 0s (0 0%) 3.4515\n",
      "0m 0s (50 0%) 2.9894\n",
      "0m 1s (100 0%) 4.0874\n",
      "0m 2s (150 0%) 3.6710\n",
      "0m 3s (200 0%) 2.6217\n",
      "0m 4s (250 0%) 2.9196\n",
      "0m 4s (300 0%) 3.0978\n",
      "0m 5s (350 0%) 4.1921\n",
      "0m 6s (400 0%) 3.0835\n",
      "0m 7s (450 0%) 3.6506\n",
      "0m 8s (500 0%) 3.6699\n",
      "0m 9s (550 0%) 2.5946\n",
      "0m 10s (600 0%) 3.6830\n",
      "0m 11s (650 0%) 2.6722\n",
      "0m 12s (700 0%) 3.1894\n",
      "0m 12s (750 0%) 3.0245\n",
      "0m 13s (800 0%) 2.1298\n",
      "0m 13s (850 0%) 2.3185\n",
      "0m 14s (900 0%) 2.4281\n",
      "0m 15s (950 0%) 2.3376\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "n_iters=1000\n",
    "plot_every=50\n",
    "print_every=50\n",
    "all_loss=[]\n",
    "total_loss=0\n",
    "start=time.time()\n",
    "for iter in range(n_iters):\n",
    "    n=random.randint(0,n_categories-1)\n",
    "    m=random.randint(0,len(dic[dic.keys()[n]])-1)\n",
    "    categoryTensor=Variable(category_one_hot(n))\n",
    "    inputTensor=Variable(dicTensor[dic.keys()[n]][m])\n",
    "    target=Variable(targetTensor[dic.keys()[n]][m])\n",
    "    output,loss=train(categoryTensor,inputTensor,target)\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_loss.append(total_loss / plot_every)\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#调试代码,调出了一个bug:RuntimeError: Assertion `cur_target >= 0 && cur_target < n_classes' failed. \n",
    "hidden=rnn.initHidden()\n",
    "category_tensor=Variable(category_one_hot(2))\n",
    "input_tensor=Variable(wordToTensor(dic['Chinese'][0]))\n",
    "output,hidden=rnn(category_tensor,input_tensor[0],hidden)\n",
    "a1=Variable(torch.LongTensor([25]))\n",
    "loss=criterion(output,a1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
